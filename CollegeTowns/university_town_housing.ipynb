{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook was created as a project for the course \"Introduction to Data Science in Python\" from the University of Michigan via Coursera.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import re\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. (`price_ratio=quarter_before_recession/recession_bottom`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this dictionary to map state names to two letter acronyms\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "umich_part_id": "021",
    "umich_partlist_id": "004"
   },
   "outputs": [],
   "source": [
    "def get_list_of_university_towns():\n",
    "    '''Returns a dataframe of university towns and their states'''\n",
    "    \n",
    "    uni_towns_imp = pd.read_csv('university_towns.txt', error_bad_lines=False, header=None, names = ['RegionName'],sep='\\n')\n",
    "    #create a field for state\n",
    "    uni_towns = uni_towns_imp\n",
    "    uni_towns['State'] = np.NaN\n",
    "    #identify the states by the presence of string \"[edit]\" and add them to the State field\n",
    "    for i in range(0,len(uni_towns)-1):\n",
    "        if re.search(r'\\[edit\\]',uni_towns['RegionName'][i]):\n",
    "            uni_towns.loc[i,'State']=uni_towns['RegionName'][i]\n",
    "    #forward fill the nulls to populate the proper state for each university town\n",
    "    uni_towns['State'] = uni_towns['State'].ffill()\n",
    "    #clean up the extra text, get rid of the state-state rows, set state as index\n",
    "    uni_towns = uni_towns[['State', 'RegionName']].replace(r'\\[edit\\]', '', regex=True).replace(r' \\(.*', '', regex=True)\n",
    "    uni_towns = uni_towns[uni_towns.State != uni_towns.RegionName].reset_index()\n",
    "    del uni_towns['index']\n",
    "\n",
    "    return uni_towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "umich_part_id": "022",
    "umich_partlist_id": "004"
   },
   "outputs": [],
   "source": [
    "def get_recession_start():\n",
    "    '''Returns the year and quarter of the recession start time'''\n",
    "    \n",
    "    gdp = pd.read_excel('gdplev.xls', header=5, parse_cols='E:G').iloc[214:]\n",
    "    del gdp['GDP in billions of current dollars']\n",
    "    gdp.columns = ['GDP 09 dlr']\n",
    "\n",
    "    #find and return the first quarter of the recession. defined by two consecuive quarters of negative GDP growth\n",
    "    rec_start = ''\n",
    "    for i in range(2,len(gdp)):\n",
    "        if ((gdp['GDP 09 dlr'][i] < gdp['GDP 09 dlr'][i-1]) and (gdp['GDP 09 dlr'][i-1] < gdp['GDP 09 dlr'][i-2])):\n",
    "            rec_start = gdp.index[i-1]\n",
    "            break\n",
    "\n",
    "    return str(rec_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_end():\n",
    "    '''Returns the year and quarter of the recession end time'''\n",
    "    \n",
    "    gdp = pd.read_excel('gdplev.xls', header=5, parse_cols='E:G').iloc[214:]\n",
    "    del gdp['GDP in billions of current dollars']\n",
    "    gdp.columns = ['GDP 09 dlr']\n",
    "    \n",
    "    rec_start_row = gdp.index.get_loc(get_recession_start())\n",
    "    #begin looking for the recession end only after one has begun\n",
    "    for i in range(rec_start_row,len(gdp)):\n",
    "        if ((gdp['GDP 09 dlr'][i] > gdp['GDP 09 dlr'][i-1]) and (gdp['GDP 09 dlr'][i-1] > gdp['GDP 09 dlr'][i-2])):\n",
    "            rec_end = gdp.index[i]\n",
    "            break\n",
    "\n",
    "    return str(rec_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_bottom():\n",
    "        '''Returns the year and quarter of the lowest GDP during the recession'''\n",
    "\n",
    "        gdp = pd.read_excel('gdplev.xls', header=5, parse_cols='E:G').iloc[214:]\n",
    "        del gdp['GDP in billions of current dollars']\n",
    "        gdp.columns = ['GDP 09 dlr']\n",
    "\n",
    "        rec_start_row = gdp.index.get_loc(get_recession_start())\n",
    "        rec_end_row = gdp.index.get_loc(get_recession_end())\n",
    "    \n",
    "        return str(gdp.iloc[rec_start_row:rec_end_row+1]['GDP 09 dlr'].idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "umich_part_id": "025",
    "umich_partlist_id": "004"
   },
   "outputs": [],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "        '''Converts the housing data from monthly to quarterly using the mean price'''\n",
    "        \n",
    "        z_housing = pd.read_csv('City_Zhvi_AllHomes.csv',index_col=[2])\n",
    "        #convert the states dictionary to a dataframe\n",
    "        states1 = pd.DataFrame(list(states.items()), columns=['abbr', 'State'])\n",
    "        #replace the state abbreviations with full state names in the housing dataframe\n",
    "        housing = pd.merge(z_housing, states1, how='left', left_index=True, right_on='abbr').set_index(['State', 'RegionName'])\n",
    "        del housing['abbr']\n",
    "        #use only data starting with January 2000\n",
    "        c = housing.columns.tolist()\n",
    "        cols = c[49:]\n",
    "        housing = housing[cols].sort_index()\n",
    "        #use pandas PeriodIndex to convert monthly data to quarterly using the mean price\n",
    "        housing = housing.groupby(pd.PeriodIndex(housing.columns, freq='q'), axis=1).mean()\n",
    "        cols1 = []\n",
    "        for x in housing.columns: cols1.append(str(x).lower())\n",
    "        housing.columns = cols1\n",
    "\n",
    "        return housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "umich_part_id": "026",
    "umich_partlist_id": "004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a p-value of 7.74416917172e-05, we reject the null hypothesis at the significance level of 0.01.\n",
      "The decline in housing prices in university towns was less than that of non-university towns during the recession in 2008-2009.\n",
      "The mean university town ratio of pre-recession to recession-bottom housing prices is 1.0614.\n",
      "That of non-university towns is 1.0794.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_ttest():\n",
    "    '''Test null hypothesis: the mean price ratio (quarter before the recession start / bottom quarter of recession)\n",
    "    of university towns is not significantly different from non-university towns'''\n",
    "    \n",
    "    housing = convert_housing_data_to_quarters()\n",
    "    #make a new dataframe for the price ratio\n",
    "    a = housing.columns.get_loc(get_recession_start()) - 1\n",
    "    b = housing.columns.get_loc(get_recession_bottom())\n",
    "    housing['price_ratio'] = housing[housing.columns[a]]/housing[housing.columns[b]]\n",
    "    housing100 = pd.DataFrame(housing['price_ratio'])\n",
    "\n",
    "    uni_towns1 = get_list_of_university_towns()\n",
    "\n",
    "    #get a dataframe of price ratios for university towns\n",
    "    housing_uni = pd.merge(housing100, uni_towns1, left_index=True, right_on=['State','RegionName']).set_index(['State', 'RegionName'])\n",
    "    #get a dataframe of price ratios for non-university towns\n",
    "    index_to_keep = housing100.index.symmetric_difference(housing_uni.index)\n",
    "    housing_non = housing100.loc[index_to_keep]\n",
    "\n",
    "    #perform an independent sample t-test\n",
    "    test1 = stats.ttest_ind(housing_uni['price_ratio'], housing_non['price_ratio'], equal_var=False, nan_policy='omit')\n",
    "\n",
    "    accrej = 'fail to reject'\n",
    "    lowhigh = 'less'\n",
    "\n",
    "    if test1.pvalue < 0.01:\n",
    "        accrej = 'reject'\n",
    "        if housing_uni['price_ratio'].mean() > housing_non['price_ratio'].mean():\n",
    "            lowhigh = 'greater'\n",
    "    else: lowhigh = 'neither greater nor less'\n",
    "\n",
    "    result = 'With a p-value of ' + str(test1.pvalue) + ', we ' + accrej + ' the null hypothesis at the significance level of 0.01.'\n",
    "    result2 = 'The decline in housing prices in university towns was ' + lowhigh + ' than that of non-university towns during the recession in 2008-2009.'\n",
    "    result3 = 'The mean university town ratio of pre-recession to recession-bottom housing prices is ' + str(round(housing_uni['price_ratio'].mean(),4)) + '.'\n",
    "    result4 = 'That of non-university towns is ' + str(round(housing_non['price_ratio'].mean(),4)) + '.'\n",
    "\n",
    "\n",
    "    return result + '\\n' + result2 + '\\n' + result3 + '\\n' + result4\n",
    "\n",
    "print(run_ttest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "umich": {
   "id": "Assignment 4",
   "version": "1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
